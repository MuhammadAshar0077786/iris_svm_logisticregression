# -*- coding: utf-8 -*-
"""iris_svm_logisticregression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w9F9l067e1KuHgGDonv29OGAGd18VVsH
"""

# import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import sklearn
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn import datasets
# %matplotlib inline

iris = datasets.load_iris()
X = iris.data[:, :5]
y = iris.target

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

from sklearn.decomposition import PCA
pca = PCA(n_components = None)
# pca = PCA(n_components = 2)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)
explained_variance = pca.explained_variance_ratio_
explained_variance

# X_train.shape
X_test.shape

pca = PCA(n_components = 2)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)
explained_variance = pca.explained_variance_ratio_
explained_variance

# svc = SVC(kernel='linear', C = 1, gamma=.6).fit(X_train, y_train)
# gnb = GaussianNB().fit(X_train, y_train)
clf = DecisionTreeClassifier().fit(X_train, y_train)

X_test.shape

x_min, x_max  = X_test[:, 0].min() -1, X_test[:, 0].max() + 1
y_min, y_max  = X_test[:, 1].min() -1, X_test[:, 1].max() + 1
h = (x_max / x_min)/100
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# plt.scatter(X_test[:, 0], X_test[:, 1], c= y_test, cmap=plt.cm.Paired) # testing data plotted
plt.scatter(X_train[:, 0], X_train[:, 1], c= y_train, cmap=plt.cm.Paired) # training data plotted
plt.xlabel('Sepal length')
plt.ylabel('sepal width')
# plt.xlim(xx.min(), xx.max())
plt.title('SVC with linear kernel')
plt.show()

plt.subplot(1,1,1)
Z = svc.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)
plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=.8)
plt.scatter(X[:, 0], X[:, 1], c= y_test, cmap=plt.cm.Paired)
plt.xlabel('Sepal length')
plt.ylabel('sepal width')
plt.xlim(xx.min(), xx.max())
plt.title('SVC with linear kernel')
plt.show()

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 0)
classifier.fit(X_train, y_train)

"""# classifiers used to fit data
#### sorry decision tree isnot workign right now
"""

# y_pred = svc.predict(X_test) # SVM
# y_pred = classifier.predict(X_test) # logistic regression
# y_pred = gnb.predict(X_test) # gaussian naive base
y_pred = clf().predict(X_test, y_test)# decision tree
y_pred

from sklearn.metrics import plot_confusion_matrix
# plot_confusion_matrix(classifier, X_test, y_test)  # logistic regression
plot_confusion_matrix(gnb, X_test, y_test) # naive bayes
plt.show()  # doctest: +SKIP

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred, normalize=False)

y_pred = svc.predict(X_test)
# y_pred = classifier.predict(X_test)

from sklearn.metrics import plot_confusion_matrix
from sklearn.svm import SVC
plot_confusion_matrix(svc, X_train, y_train)
plt.show()